#!/usr/bin/env python3
"""
åˆ—åå¤‰æ›ãƒãƒƒãƒ—ã§æ”¹å–„å¯èƒ½ãªç®‡æ‰€ã‚’åˆ†æ

ãƒãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰å¯¾å¿œç‡ãŒä½ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŠ½å‡ºã—ã€
RS2024ã¨éå»ãƒ‡ãƒ¼ã‚¿ã®åˆ—åå·®åˆ†ã‚’åˆ†æã—ã¦ã€ãƒãƒƒãƒ”ãƒ³ã‚°ã§
åŸ‹ã‚ã‚‰ã‚Œãã†ãªç®‡æ‰€ã‚’æ´—ã„å‡ºã™
"""

import pandas as pd
from pathlib import Path
from typing import Dict, List, Set, Tuple
import sys

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def get_column_diff(rs2024_file: Path, historical_file: Path) -> Tuple[List[str], List[str], List[str]]:
    """
    RS2024ã¨éå»ãƒ‡ãƒ¼ã‚¿ã®åˆ—åå·®åˆ†ã‚’å–å¾—

    Returns:
        (RS2024ã®ã¿ã«ã‚ã‚‹åˆ—, éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ã«ã‚ã‚‹åˆ—, å…±é€šåˆ—)
    """
    rs_df = pd.read_csv(rs2024_file, nrows=0, encoding='utf-8-sig')
    hist_df = pd.read_csv(historical_file, nrows=0, encoding='utf-8-sig')

    rs_cols = set(rs_df.columns)
    hist_cols = set(hist_df.columns)

    only_rs = sorted(rs_cols - hist_cols)
    only_hist = sorted(hist_cols - rs_cols)
    common = sorted(rs_cols & hist_cols)

    return only_rs, only_hist, common


def normalize_for_similarity(text: str) -> str:
    """é¡ä¼¼æ€§åˆ¤å®šç”¨ã®æ­£è¦åŒ–"""
    # æ‹¬å¼§å†…ã‚’å‰Šé™¤
    import re
    text = re.sub(r'[ï¼ˆ(].*?[ï¼‰)]', '', text)
    # è¨˜å·ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤
    text = text.replace('ï¼ˆ', '').replace('ï¼‰', '').replace('(', '').replace(')', '')
    text = text.replace('ã€€', '').replace(' ', '')
    text = text.replace('ãƒ»', '').replace('-', '').replace('ãƒ¼', '')
    text = text.replace('ã€', '').replace('ã€‚', '')
    return text


def find_similar_columns(rs_col: str, hist_cols: List[str]) -> List[Tuple[str, float]]:
    """
    RS2024ã®åˆ—ã¨é¡ä¼¼ã™ã‚‹éå»ãƒ‡ãƒ¼ã‚¿ã®åˆ—ã‚’æ¤œç´¢

    Returns:
        (éå»ãƒ‡ãƒ¼ã‚¿åˆ—å, é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢)ã®ãƒªã‚¹ãƒˆ
    """
    rs_normalized = normalize_for_similarity(rs_col)
    candidates = []

    for hist_col in hist_cols:
        hist_normalized = normalize_for_similarity(hist_col)

        # å®Œå…¨ä¸€è‡´
        if rs_normalized == hist_normalized:
            candidates.append((hist_col, 1.0))
            continue

        # éƒ¨åˆ†ä¸€è‡´ï¼ˆåŒ…å«é–¢ä¿‚ï¼‰
        if rs_normalized in hist_normalized or hist_normalized in rs_normalized:
            similarity = min(len(rs_normalized), len(hist_normalized)) / max(len(rs_normalized), len(hist_normalized))
            candidates.append((hist_col, similarity))
            continue

        # å…±é€šéƒ¨åˆ†æ–‡å­—åˆ—ã®å‰²åˆ
        common_chars = set(rs_normalized) & set(hist_normalized)
        if common_chars:
            similarity = len(common_chars) / max(len(set(rs_normalized)), len(set(hist_normalized)))
            if similarity > 0.5:  # 50%ä»¥ä¸Šå…±é€š
                candidates.append((hist_col, similarity))

    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    candidates.sort(key=lambda x: x[1], reverse=True)
    return candidates[:3]  # ä¸Šä½3ä»¶


def analyze_table(table_id: str, year: int = 2023) -> Dict:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆ—åå·®åˆ†ã‚’åˆ†æ"""
    rs2024_dir = Path("/tmp/rs2024_extracted")
    output_dir = project_root / "output" / "processed" / f"year_{year}"

    # RS2024ãƒ•ã‚¡ã‚¤ãƒ«
    rs_files = list(rs2024_dir.glob(f"{table_id}_*.csv"))
    if not rs_files:
        return {"error": "RS2024ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

    # éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
    hist_files = list(output_dir.glob(f"{table_id}_{year}_*.csv"))
    if not hist_files:
        return {"error": f"{year}å¹´ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

    # åˆ—åå·®åˆ†å–å¾—
    only_rs, only_hist, common = get_column_diff(rs_files[0], hist_files[0])

    # ãƒãƒƒãƒ”ãƒ³ã‚°å€™è£œã‚’æ¤œç´¢
    mapping_suggestions = {}
    for rs_col in only_rs:
        similar = find_similar_columns(rs_col, only_hist)
        if similar:
            mapping_suggestions[rs_col] = similar

    return {
        "rs2024_file": rs_files[0].name,
        "historical_file": hist_files[0].name,
        "total_rs_cols": len(only_rs) + len(common),
        "total_hist_cols": len(only_hist) + len(common),
        "common_cols": len(common),
        "only_rs": only_rs,
        "only_hist": only_hist,
        "mapping_suggestions": mapping_suggestions,
        "coverage_rate": len(common) / (len(only_rs) + len(common)) * 100 if (len(only_rs) + len(common)) > 0 else 0
    }


def generate_report():
    """æ”¹å–„æ©Ÿä¼šãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    # å¯¾å¿œç‡ãŒä½ã„ã€œä¸­ç¨‹åº¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å„ªå…ˆçš„ã«åˆ†æ
    priority_tables = [
        ("1-2", "åŸºæœ¬æƒ…å ±_äº‹æ¥­æ¦‚è¦", 65.6),
        ("2-1", "äºˆç®—ãƒ»åŸ·è¡Œ_ã‚µãƒãƒª", 45.5),
        ("5-1", "æ”¯å‡ºå…ˆ_æ”¯å‡ºæƒ…å ±", 68.8),
        ("4-1", "ç‚¹æ¤œãƒ»è©•ä¾¡", 73.0),
        ("5-3", "æ”¯å‡ºå…ˆ_è²»ç›®ãƒ»ä½¿é€”", 85.0),
        ("2-2", "äºˆç®—ãƒ»åŸ·è¡Œ_äºˆç®—ç¨®åˆ¥", 61.5),
        ("5-4", "æ”¯å‡ºå…ˆ_å›½åº«å‚µå‹™è² æ‹…è¡Œç‚º", 48.1),
    ]

    lines = []
    lines.append("# åˆ—åå¤‰æ›ãƒãƒƒãƒ—ã«ã‚ˆã‚‹æ”¹å–„æ©Ÿä¼šåˆ†æ")
    lines.append("")
    lines.append(f"åˆ†ææ—¥æ™‚: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("## æ¦‚è¦")
    lines.append("")
    lines.append("å¯¾å¿œç‡ãŒä½ã„ã€œä¸­ç¨‹åº¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¤ã„ã¦ã€RS2024ã¨2023å¹´ãƒ‡ãƒ¼ã‚¿ã®åˆ—åå·®åˆ†ã‚’åˆ†æã—ã€")
    lines.append("åˆ—åå¤‰æ›ãƒãƒƒãƒ—ã§åŸ‹ã‚ã‚‰ã‚Œãã†ãªç®‡æ‰€ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
    lines.append("")

    all_suggestions = {}

    for table_id, table_name, current_rate in priority_tables:
        print(f"ğŸ“Š åˆ†æä¸­: {table_id} - {table_name} (ç¾åœ¨{current_rate}%)")

        result = analyze_table(table_id, year=2023)

        if "error" in result:
            print(f"  âš ï¸  {result['error']}")
            continue

        lines.append("---")
        lines.append("")
        lines.append(f"## {table_id}: {table_name}")
        lines.append("")
        lines.append(f"**ç¾åœ¨ã®å¯¾å¿œç‡**: {current_rate}%")
        lines.append(f"**RS2024åˆ—æ•°**: {result['total_rs_cols']}åˆ—")
        lines.append(f"**2023å¹´åˆ—æ•°**: {result['total_hist_cols']}åˆ—")
        lines.append(f"**å…±é€šåˆ—æ•°**: {result['common_cols']}åˆ—")
        lines.append("")

        # RS2024ã®ã¿ã«ã‚ã‚‹åˆ—
        lines.append("### RS2024ã«ã®ã¿å­˜åœ¨ã™ã‚‹åˆ—ï¼ˆæ¬ ã‘ã¦ã„ã‚‹åˆ—ï¼‰")
        lines.append("")
        lines.append(f"**ä»¶æ•°**: {len(result['only_rs'])}åˆ—")
        lines.append("")

        if result['mapping_suggestions']:
            lines.append("#### ãƒãƒƒãƒ”ãƒ³ã‚°å€™è£œã‚ã‚Š âœ¨")
            lines.append("")
            lines.append("| RS2024åˆ—å | é¡ä¼¼ã™ã‚‹2023å¹´åˆ—å | é¡ä¼¼åº¦ | æ¨å¥¨åº¦ |")
            lines.append("|------------|-------------------|--------|--------|")

            for rs_col, candidates in result['mapping_suggestions'].items():
                for hist_col, similarity in candidates:
                    priority = "é«˜" if similarity >= 0.8 else "ä¸­" if similarity >= 0.6 else "ä½"
                    lines.append(f"| {rs_col[:40]} | {hist_col[:40]} | {similarity:.1%} | {priority} |")

                    # å…¨ä½“ã®æ¨å¥¨ãƒãƒƒãƒ”ãƒ³ã‚°ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    if table_id not in all_suggestions:
                        all_suggestions[table_id] = []
                    all_suggestions[table_id].append({
                        "rs_col": rs_col,
                        "hist_col": hist_col,
                        "similarity": similarity,
                        "priority": priority
                    })

            lines.append("")

        # ãƒãƒƒãƒ”ãƒ³ã‚°å€™è£œã®ãªã„åˆ—
        no_mapping = [col for col in result['only_rs'] if col not in result['mapping_suggestions']]
        if no_mapping:
            lines.append("#### ãƒãƒƒãƒ”ãƒ³ã‚°å€™è£œãªã—ï¼ˆæ–°è¦å®Ÿè£…ãŒå¿…è¦ï¼‰")
            lines.append("")
            for col in no_mapping[:10]:  # æœ€åˆã®10ä»¶ã®ã¿
                lines.append(f"- {col}")
            if len(no_mapping) > 10:
                lines.append(f"- ...ä»–{len(no_mapping) - 10}ä»¶")
            lines.append("")

        # 2023å¹´ã®ã¿ã«ã‚ã‚‹åˆ—ï¼ˆRS2024ã§å‰Šé™¤ã•ã‚ŒãŸåˆ—ï¼‰
        if result['only_hist']:
            lines.append("### 2023å¹´ã«ã®ã¿å­˜åœ¨ã™ã‚‹åˆ—ï¼ˆRS2024ã§å‰Šé™¤ï¼‰")
            lines.append("")
            lines.append(f"**ä»¶æ•°**: {len(result['only_hist'])}åˆ—")
            lines.append("")
            for col in result['only_hist'][:5]:
                lines.append(f"- {col}")
            if len(result['only_hist']) > 5:
                lines.append(f"- ...ä»–{len(result['only_hist']) - 5}ä»¶")
            lines.append("")

        print(f"  âœ“ ãƒãƒƒãƒ”ãƒ³ã‚°å€™è£œ: {len(result['mapping_suggestions'])}ä»¶")

    # ã‚µãƒãƒª
    lines.append("---")
    lines.append("")
    lines.append("## æ¨å¥¨ãƒãƒƒãƒ”ãƒ³ã‚°ä¸€è¦§ï¼ˆå„ªå…ˆåº¦é †ï¼‰")
    lines.append("")

    high_priority = []
    medium_priority = []

    for table_id, suggestions in all_suggestions.items():
        for sug in suggestions:
            if sug['priority'] == 'é«˜':
                high_priority.append((table_id, sug))
            elif sug['priority'] == 'ä¸­':
                medium_priority.append((table_id, sug))

    if high_priority:
        lines.append("### é«˜å„ªå…ˆåº¦ï¼ˆé¡ä¼¼åº¦80%ä»¥ä¸Šï¼‰")
        lines.append("")
        lines.append("| ãƒ†ãƒ¼ãƒ–ãƒ« | RS2024åˆ—å | â†’ | 2023å¹´åˆ—å | é¡ä¼¼åº¦ |")
        lines.append("|---------|-----------|---|-----------|--------|")
        for table_id, sug in high_priority:
            lines.append(f"| {table_id} | {sug['rs_col'][:30]} | â†’ | {sug['hist_col'][:30]} | {sug['similarity']:.1%} |")
        lines.append("")

    if medium_priority:
        lines.append("### ä¸­å„ªå…ˆåº¦ï¼ˆé¡ä¼¼åº¦60-80%ï¼‰")
        lines.append("")
        lines.append("| ãƒ†ãƒ¼ãƒ–ãƒ« | RS2024åˆ—å | â†’ | 2023å¹´åˆ—å | é¡ä¼¼åº¦ |")
        lines.append("|---------|-----------|---|-----------|--------|")
        for table_id, sug in medium_priority[:20]:  # æœ€åˆã®20ä»¶
            lines.append(f"| {table_id} | {sug['rs_col'][:30]} | â†’ | {sug['hist_col'][:30]} | {sug['similarity']:.1%} |")
        lines.append("")

    return "\n".join(lines)


def main():
    print("=" * 80)
    print("åˆ—åå¤‰æ›ãƒãƒƒãƒ—ã«ã‚ˆã‚‹æ”¹å–„æ©Ÿä¼šåˆ†æ")
    print("=" * 80)
    print()

    report = generate_report()

    output_file = project_root / "data_quality" / "mapping_opportunities.md"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(report)

    print()
    print("=" * 80)
    print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {output_file}")
    print("=" * 80)


if __name__ == "__main__":
    main()
